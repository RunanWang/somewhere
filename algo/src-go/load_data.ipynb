{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://182.92.196.182:27017/\")\n",
    "mydb = myclient[\"kit\"]\n",
    "rec_col = mydb[\"records\"]\n",
    "item_col = mydb[\"items\"]\n",
    "user_col = mydb[\"users\"]\n",
    "store_col = mydb[\"stores\"]\n",
    "records = rec_col.find({},{\"_id\":0, \"query\":0})\n",
    "items = item_col.find()\n",
    "users = user_col.find()\n",
    "stores = store_col.find()\n",
    "# for item in stores:\n",
    "#     print(item)\n",
    "df_rec = pd.DataFrame(list(records))\n",
    "df_item = pd.DataFrame(list(items))\n",
    "df_user = pd.DataFrame(list(users))\n",
    "df_store = pd.DataFrame(list(stores))\n",
    "# print(df_rec)\n",
    "# print(df_item)\n",
    "# print(df_user)\n",
    "# print(df_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_rec)\n",
    "df_item = df_item.rename(columns={'_id':'item_id'})\n",
    "df_item.set_index(['item_id'],inplace=True)\n",
    "# print(df_item)\n",
    "df_user = df_user.rename(columns={'_id':'user_id'})\n",
    "df_user.set_index(['user_id'],inplace=True)\n",
    "df_store = df_store.rename(columns={'_id':'store_id','timestamp':'store_timestamp'})\n",
    "df_store.set_index(['store_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_rec.set_index(['item_id'])\n",
    "df_result = pd.concat([df_result, df_item], axis = 1, join='inner')\n",
    "df_result = df_result.reset_index()\n",
    "# print(df_result)\n",
    "df_result.set_index(['user_id'],inplace=True)\n",
    "# print(df_result)\n",
    "df_result = pd.concat([df_result, df_user], axis = 1, join='inner')\n",
    "df_result = df_result.reset_index()\n",
    "# print(df_user)\n",
    "# print(df_result)\n",
    "df_result.set_index(['store_id'],inplace=True)\n",
    "df_result = pd.concat([df_result, df_store], axis = 1, join='inner')\n",
    "df_result = df_result.reset_index()\n",
    "# df_result.drop(['item_id'])\n",
    "df_result.to_csv(\"./result.csv\",encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_id = [\n",
    "    \"store_id\", \"user_id\", \"item_id\"\n",
    "]\n",
    "header_cate = [\n",
    "    \"item_brand\", \"item_name\",  \"user_gender\", \"store_city\"\n",
    "]\n",
    "header_cont=[\n",
    "    \"item_price\", \"item_salecount\", \"item_score\",  \"store_level\", \"item_timestamp\", \"store_timestamp\"\n",
    "]\n",
    "header_cont_user=[\n",
    "    \"user_age\", \"user_historysum\"\n",
    "]\n",
    "header_time=[\n",
    "    \"timestamp\", \"item_timestamp\", \"user_timestamp\", \"store_timestamp\"\n",
    "]\n",
    "header_label=[\n",
    "    \"is_trade\"\n",
    "]\n",
    "df_cont = df_result[header_cont]\n",
    "df_cont_user = df_result[header_cont_user]\n",
    "df_id = df_result[header_id]\n",
    "df_cate = df_result[header_cate]\n",
    "df_time = df_result[header_time]\n",
    "df_label = df_result[header_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5\n",
      "0  1.0  1.0  0.0  0.0  0.0  1.0\n",
      "1  1.0  1.0  0.0  0.0  0.0  1.0\n",
      "2  1.0  1.0  0.0  0.0  0.0  1.0\n",
      "3  0.0  0.0  1.0  1.0  1.0  0.0\n",
      "4  1.0  1.0  0.0  0.0  0.0  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\APP\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(df_cont)\n",
    "df_cont = pd.DataFrame(scaled)\n",
    "print(df_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_gender  item_brand_哇哈哈  item_brand_清风  item_name_矿泉水  item_name_餐巾纸  \\\n",
      "0            1               1              0              1              0   \n",
      "1            1               1              0              1              0   \n",
      "2            1               1              0              1              0   \n",
      "3            1               0              1              0              1   \n",
      "4            2               1              0              1              0   \n",
      "\n",
      "   store_city_拉萨  store_city_长春  \n",
      "0              1              0  \n",
      "1              1              0  \n",
      "2              1              0  \n",
      "3              0              1  \n",
      "4              1              0  \n"
     ]
    }
   ],
   "source": [
    "df_cate = pd.get_dummies(df_cate)\n",
    "print(df_cate)\n",
    "frame = [df_cont,df_cont_user, df_cate]\n",
    "X = pd.concat(frame, axis=1)\n",
    "y = df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.6944 - acc: 0.2000\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 2/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3716 - acc: 0.500 - 0s 997us/step - loss: 0.6820 - acc: 0.2000\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6697 - acc: 0.2000\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6507 - acc: 0.2000\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6339 - acc: 0.2000\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6129 - acc: 0.2000\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5871 - acc: 0.2000\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5610 - acc: 0.2000\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5286 - acc: 0.2000\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5076 - acc: 0.2000\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "     0    1    2    3    4    5  user_age  user_historysum  user_gender  \\\n",
      "0  1.0  1.0  0.0  0.0  0.0  1.0        23              0.0            1   \n",
      "1  1.0  1.0  0.0  0.0  0.0  1.0        23              0.0            1   \n",
      "2  1.0  1.0  0.0  0.0  0.0  1.0        23              0.0            1   \n",
      "3  0.0  0.0  1.0  1.0  1.0  0.0        23              0.0            1   \n",
      "4  1.0  1.0  0.0  0.0  0.0  1.0        18              0.0            2   \n",
      "\n",
      "   item_brand_哇哈哈  item_brand_清风  item_name_矿泉水  item_name_餐巾纸  store_city_拉萨  \\\n",
      "0               1              0              1              0              1   \n",
      "1               1              0              1              0              1   \n",
      "2               1              0              1              0              1   \n",
      "3               0              1              0              1              0   \n",
      "4               1              0              1              0              1   \n",
      "\n",
      "   store_city_长春  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              1  \n",
      "4              0  \n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Lambda, multiply\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import utils as utils\n",
    "import h5py\n",
    "\n",
    "MODEL_PATH = './mlr_model.h5'\n",
    "\n",
    "def keras_sum_layer_output_shape(input_shape):\n",
    "    # a function calculate the shape(equal to 1 in the sum func)\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 2\n",
    "    shape[-1] = 1\n",
    "    return tuple(shape)\n",
    "\n",
    "\n",
    "def keras_sum_layer(x):\n",
    "    # a function to take sum of the layers\n",
    "    return K.sum(x, axis=1, keepdims=True)\n",
    "\n",
    "wide_m = 12\n",
    "input_wide = Input(shape=(X.shape[1], ))\n",
    "# 第二层为LR和权重层，采用l2正则化项\n",
    "wide_divide = Dense(wide_m,\n",
    "                    activation='softmax',\n",
    "                    bias_regularizer=regularizers.l2(0.01))(input_wide)\n",
    "wide_fit = Dense(wide_m,\n",
    "                 activation='sigmoid',\n",
    "                 bias_regularizer=regularizers.l2(0.01))(input_wide)\n",
    "wide_ele = multiply([wide_divide, wide_fit])\n",
    "out = Lambda(keras_sum_layer,\n",
    "             output_shape=keras_sum_layer_output_shape)(wide_ele)\n",
    "model = Model(inputs=input_wide, outputs=out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X,\n",
    "          y,\n",
    "          epochs=10,\n",
    "          batch_size=2,\n",
    "          callbacks=[\n",
    "              utils.roc_callback(training_data=[X, y], validation_data=[X, y])\n",
    "          ])\n",
    "print(X)\n",
    "model.save(MODEL_PATH)\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as file:\n",
    "    file.write(model_json)\n",
    "model.save_weights('model.json.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
