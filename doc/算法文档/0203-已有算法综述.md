## 研究广告模型时为什么要研究CTR

CTR也称转化率，衡量的是用户点击推荐项目的概率。由于广告系统的目标就是将点击率最大化，所以预测待推荐项目的转化率，并把项目按照转化率由高到低排序推荐给用户是推荐系统的一种推荐方法。在另一个方面，CTR在衡量广告竞价时也有重要的作用，因此在研究广告模型时需要研究如何尽可能准确地预测CTR。

预测CTR目前面临的挑战是如何挖掘特征之间的关联。低维和高维的特征组合可能会交织成一张巨大的特征网络。例如根据调查数据，在接近中午用餐时间时，食品类商品的浏览量和购买量会出现一个峰值；男性用户对印有RPG元素的T恤更有购买倾向等等。单单依靠特征工程来构造如此复杂的特征网络是不实际的。因此传统的LR和MF等模型渐渐被能够组合特征的DNN模型取代。在Deep&Wide模型出现之后，模型兼顾了低维的特征直接对结果的影响和组合特征对结果的影响。所以在之后研究的重点转向了如何为Deep&Wide提供更好的组合特征。

## CTR现有的算法

### 基础机器学习模型

LR-Logistic Regression简单而有效，将诸如查询信息、用户信息等特征抽象成值。LR模型已经被广泛运用在点击率预测的场景中。但不能发现潜在的特征或者发掘复杂的关系。

MF-matrix factorization（奇异值矩阵）和进过改进后的FM-Factorization Machines（因式分解机）通过矩阵发现特征之间成对的关系，但是忽略了多个特征之间的高阶的关系和多条记录之间的序列化的关系。

这些传统的点击率预测模型都只把单次的特征作为预测点击率的唯一输入，而没有把点击事件的发生与用户的历史信息结合起来。

### 深度学习模型

RNN可以把用户的行为序列进行模拟，但是预测用户的行为时是不会改变的。但是在真实的场景中，用户对待广告的态度会随着时间不断变化，由于RNN使用了固定的传播路径，所以有一定的局限性。

在单次预测中，CNN可以挖掘复杂的组合特征逻辑。运用池化层和卷积层可以发掘随时间序列变化的特征。

### CCPM

《A Convolutional Click Prediction Model》

引用理由：将CTR问题研究方向转向了如何依靠深度学习网络来自动地组合特征。

基于卷积，能够提取出local-global（局部）关键特征，在单个预测和序列预测上都有较好的效果。输入是经过序列化之后的用户行为序列，卷积层用于提取局部特征，动态池化层提取关键特征。

#### 详细的模型

用一个卷积层，先做一个embedding

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190427102114461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTIxNTEyODM=,size_16,color_FFFFFF,t_70)

通过一个(width, 1)的kernel进行对特征的embedding矩阵进行二维卷积，其中width表示的每次对连续的width个特征进行卷积运算，之后使用一个Flexible pooling机制进行池化操作进行特征聚合和压缩表示，堆叠若干层后将得到特征矩阵作为MLP的输入，得到最终的预测结果。

#### 指标

数据集是Avazu and Yoochoose

指标是logloss

### Wide&Deep

《Wide & Deep Learning for Recommender Systems》

引用理由：既保留了wide部分对特征的记忆能力，又用deep深度模型进行特征组合，加强了泛化能力。

模型采用LR和DNN组合的方式来进行，最后用一个神经元将两部分连接到一起，训练时一起训练。对分类的特征采用先onehot再embedding的模式，最后搭建成神经网络。两部分的输入是相同的，但是wide的部分并没有使用embedding之后的结果。是记忆能力和泛化能力的综合权衡。

#### 详细模型

![1580798130838](C:\Users\Ryanw\AppData\Roaming\Typora\typora-user-images\1580798130838.png)

#### 指标

单用deep、单用wide和两者结合，AUC。数据集Google自家未透露。

### DeepFM

《DeepFM: A Factorization-Machine based Neural Network for CTR Prediction》

引用理由：证明了改进wide部分可以提升deep&wide的效果。

模型的基础是Deep&Wide模型，输入首先做onehot处理，然后做统一的embedding处理，对embedding之后的数据一方面输入DNN做Deep部分，另一方面输入FM做因式分解机部分，最终用一个神经元输出。相当于把deep&wide中wide部分换成了二维的FM。

#### 详细模型

![img](https://upload-images.jianshu.io/upload_images/4155986-21fa429e42108e99.png?imageMogr2/auto-orient/strip|imageView2/2/w/535/format/webp)

#### 指标

数据集用criteo

指标用logloss和AUC

### NFM

《Neural Factorization Machines for Sparse Predictive Analytics》

引用理由：证明了改进deep部分可以提升deep&wide的效果。

FM中是仅仅组合了二维的特征，NFM中是通过加入隐含层的方式形成多维的组合特征。

#### 详细模型

![这里写图片描述](https://img-blog.csdn.net/20180820200738278?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQ0NzU0Nzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### RNN（LSTM）

《Collaborative Filtering with Recurrent Neural Networks》

引用理由：证明了RNN在序列化下有较好的表现，可以预测用户的兴趣变化。

提出将协作过滤看作是一个序列预测问题，并且在给出这种解释的情况下，将长短期记忆（LSTM）的递归神经网络应用于协作过滤。LSTM在项目覆盖率和短期预测方面远远优于其他方法。推荐不仅应该基于消费的项目，也应基于消费的顺序。最后的实验结果表明，LSTM在Movielens和Netflix数据集上产生非常好的结果，并且在短期预测和项目覆盖方面特别好。

#### 指标

用了movielens的数据集，觉得可参考。

